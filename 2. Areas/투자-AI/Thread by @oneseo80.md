---
title: Thread by @oneseo80
source: https://x.com/oneseo80/status/1894985302110077249
author:
  - "[[@oneseo80]]"
published: 2025-02-26
created: 2025-02-28
description: 진짜 가슴이 웅장해지는 부분(편하게 반말로 하겠음) 바이오 조금 공부했다면 "DBTL(Design-Build-Test-Learn)" 이라는 말을 들어봤을 꺼야. 연구자가 가설을 세우고(Design) → 실험을 설계(Build) → 실험을 수행(Tes
tags:
  - clippings
  - 투자/AI
---
---
## 요약
- DBTL 프로세스가 AI로 인해 바뀌고 있다. 특히, "D(Design)"와 "T(Test)"의 개념이 바뀌고 있다.
- Design: 연구 방식의 핵심이 "졸라 똑똑한 인간"이 아니라, "대규모 데이터"로 이동
- Test: . 상관관계만 파악되면 실제로 컴퓨터가 아닌 리얼월드에서도 똑같이 유효한지만 확인하면 된다.


---



**Goose Farmer** @oneseo80 2025-02-26

진짜 가슴이 웅장해지는 부분(편하게 반말로 하겠음)

바이오 조금 공부했다면 "DBTL(Design-Build-Test-Learn)" 이라는 말을 들어봤을 꺼야. 연구자가 가설을 세우고(Design) → 실험을 설계(Build) → 실험을 수행(Test) → 결과 분석 및 학습(Learn) 하는 거지.

아래 Ginkgo의 발표는 이런 DBTL 프로세스가 AI로 인해 바뀌고 있다는 거야. 특히, "D(Design)"와 "T(Test)"의 개념이 바뀌고 있어.

"D(Design)" 에서 인간이 아닌 AI가 가설을 세운다는 게 포인트야. 예전에는 인간 연구자가 인과관계를 중심으로 가설을 세우고 이를 검증했다면, 지금은 AI가 제안하는 상관관계를 중심으로 가설을 세우고 검증해. 여기서 주목할 건 "인과관계"가 "상관관계"로 바뀐다는 점이야. 이게 무슨 의미인지 알지? 졸라 머리 싸매고 정확한 원인과 결과를 파악하는 것보다는 대규모로 데이터 때려 넣어서 패턴만 파악하면 된다는 거야. 즉, 연구 방식의 핵심이 "졸라 똑똑한 인간"이 아니라, "대규모 데이터"로 이동한다는 거지. 이렇게 되면, 연구의 목표 자체가 "어떻게 하면 AI가 학습하기 좋은 데이터를 만들 수 있을까"로 변해.

"T(Test)" 에서 AI 기반의 연구방식은 기존 방식과 비교하면, 검증을 하기 위한 실험 과정이 대폭 줄어들고 초점(focus)가 매우 정밀해져. 예전에는 연구자의 인과관계를 뒷받침하기 위한 유연하고, 다양한 실험이 필요했어. 근데 이제는 그렇지 않아. 상관관계만 파악되면 실제로 컴퓨터가 아닌 리얼월드에서도 똑같이 유효한지만 확인하면 되거든.

즉 예전의 DBTL이 AI 시대에는 "대량으로 실험 데이터 생성 → AI 모델 학습 → AI가 새로운 가설 생성 → 실험을 통한 검증 → 데이터 피드백 및 개선"으로 바뀌게 되는 거지.

이런 방식이 자리 잡으면 연구 자체가 "가설을 검증"하는 것에서 "가설을 발견"하는 방식으로 변화할꺼야. 과거에는 연구자가 가설을 세우고 실험을 통해 검증하고, 데이터를 수집하는 방식이었지만, 이제는 AI가 데이터를 기반으로 새로운 가설을 제시하는 구조가 되는 거지.

AI가 점점 발전하면서 연구자들이 데이터 관리와 모델 최적화에 집중하고, 실험 자체는 자동화될 가능성이 높아. 특히 임상 이전 단계에서 AI가 얼마나 신뢰성 높은 예측을 할 수 있느냐가 핵심 경쟁력이 될 꺼야. 신뢰성 높은 예측을 하려면 뭐가 필요할까? 맞아. 바로 "고품질의 데이터"야.

Ginkgo에서 신사업인 Datapoint와 Lab Automation으로 노리는 부분이 바로 여기야.

첫번째, 데이터가 중요하다고 했잖아. 그러니까 AI가 학습하기 쉬운 표준화된 데이터를 빠르고, 쉽고, 저렴하게, 대규모로 공급해주겠다는 거야. 그게 Datapoint의 핵심이야. 근데 한번 만든 데이터를 고객에게 전달하면, 그대로 끝나는 걸까? 똑같은 데이터는 Ginkgo에 남아있지 않을까? 물론 처음에는 맞춤형으로 데이터를 만들겠지만, 그런 데이터가 쌓이고 대규모로 생산한다면 규모의 경제를 달성하지 않을까?

두번째, 데이터를 직접 만들고 싶어하는 고객사들이 있어. 그러면 그거 Ginkgo에서 안만들고, 고객사 스스로 만들 수 있도록 자동화 장비를 설치해주겠다는게 RAC이야. 그런데 이걸 모듈화해서 굳이 비싼 대규모 실험실을 구축할 필요없이 필요한 모듈만 구입하고, 나중에 더 필요한 모듈만 추가로 구매해서 확장할 수 있게 하는 거지. 이건 아마 Datapoint보다 좀 더 장기적으로 봐야할 꺼야. 도입 자체가 조금 고민이 필요한 부분이라, 일단 소규모로 사서 써보고 확장하는 데 조금 시간이 걸릴꺼야.

가만히 생각해봐. 이게 성공만 한다면, 데이터를 Ginkgo에서 갖다 쓰고, 데이터 안 갖다쓰면 실험실 장비를 Ginkgo 플랫폼으로 돌리라는 거야. 다시 말해 Ginkgo가 신약 개발 인프라(소프트웨어, 하드웨어)를 모두 먹게 되는 거지.

Ginkgo 얘네 좀 무서워졌어. 물론 시간이 걸릴 꺼야. 근데, 아침부터 가슴이 웅장해지는 건 어쩔수 없네.

> 2025-02-26
> 
> 깅코 어닝콜 中 ( 인상깊었던 부분 )
> 
> 작년에 이 분야로 뛰어드는 것은 어느 정도 리스크가 있는 결정이었지만, 지금 돌아보면 그 선택이 매우 성공적이었다고 생각합니다.
> 
> 그 이유는 바이오텍 업계에서
> 
> AI 모델을 위한 대규모 데이터 자산(Large Data Assets)에 대한 고객 수요가 증가하고 있기
> 
> ![Image](https://pbs.twimg.com/media/GkxWblZa0AAdmQb?format=jpg&name=large)

---

**엔팔좋아** @NPjoa\_Hodl [2025-02-27](https://x.com/NPjoa_Hodl/status/1895016876851503552)

감사합니다 다 읽어보니

그림이 더 잘보이네요🤩

깅코를 신사업부 이후로 알게되서

잃어버렸던 체스말 하나 챙긴 기분입니다 ㅎㅎ

---

**Goose Farmer** @oneseo80 [2025-02-27](https://x.com/oneseo80/status/1895037938783891620)

저는 어닝콜 듣고 가슴이 웅장해져 추매로 대응했습니다 ㅋㅋ

---

