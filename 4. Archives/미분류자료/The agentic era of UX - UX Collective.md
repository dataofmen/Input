[[ReadItLater]] [[Article]]

# [The agentic era of UX - UX Collective](https://uxdesign.cc/the-agentic-era-of-ux-4b58634e410b)

## The future of digital experience is here — but it’s being minced into microscopic use cases.

[

![Alex Klein](Attachment/Alex%20Klein.png)



](https://medium.com/@alexklein_teamhuman?source=post_page---byline--4b58634e410b--------------------------------)

[

![UX Collective](Attachment/UX%20Collective.png)



](https://uxdesign.cc/?source=post_page---byline--4b58634e410b--------------------------------)

*Serving AI features to users like little peas — instead of a substantial meal.*

**TLDR: The thing missing from AI user experience is, well, the experience.**

It’s been 17 months since the tech gods bestowed generative artificial intelligence on us. Here’s a state of the union for AI UX:

1.  A bunch of companies shipped either an AI summary feature or a RAG-based search feature
2.  They all declared their products to be AI-powered
3.  We all clapped and clapped — until we couldn’t clap anymore

If we’re being honest with ourselves, the transformative new era hasn’t been *so* transformative yet. We were given the [‘most profound technology since fire,’](https://fortune.com/2023/04/17/sundar-pichai-a-i-more-profound-than-fire-electricity/) and companies have used it to make fake candles.

I’ve appreciated the work of many designers who have pushed to remind us of our golden rule: technology must [solve real user needs](https://shapeofai.substack.com/p/exploring-the-spectrum-of-needfulness). Or, more directly, AI shouldn’t be built just for the sake of AI.

The next stage of this argument is to tackle a thornier problem: AI is seen as a loose-leaf solution rather than a new paradigm of user experience. We know that the value of UX comes from understanding a user’s entire journey and holistically supporting them along the way; yet, AI is being tacked onto today’s experiences to solve micro user needs instead of transforming from end-to-end.

Companies are picking individual use cases, and serving them up to users like little peas, rather than weaving the ingredients into a substantial meal.

This reductive approach is exacerbated by hungry consultants, who are all selling a similar offering:

-   Find 10–20 use cases for GenAI
-   Prioritize the field by analyzing complexity and value
-   Implement a chatbot that tackles one or two applications

There are, of course, exceptions. For instance, [Loom’s AI launch](https://www.loom.com/ai) was a great example of going beyond an individual feature to consider the user’s entire journey. It would have been very reasonable for Loom, a video recording solution, to ship an AI transcription feature and call it a day. Instead, they supported the user’s entire workflow and created the functionality to record a video, transcribe it automatically, edit it, and file a Jira ticket. That end-to-end perspective is what’s missing in AI UX today.

If we’re being real, to fully deliver this end-to-end vision, we need a bit more from the foundational technology — but we’re quickly getting there.

## We’re entering the agentic era of AI

AI agents have become the next frontier in the evolution of large language models (LLM). In the last few weeks alone, it’s been all the AI leaders can talk about. OpenAI’s Sam Altman called agents AI’s [“killer function.”](https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-helpful-agents-are-poised-to-become-ais-killer-function/) Google’s Demis Hassabis called agents [“the next big step change.”](https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artificial-intelligence-scale/?bxid=&cndid=&esrc=) Anthropic’s Dario Amodei called agents the next [“significant unlock”](https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html) and predicted that we are only three to 18 months away from this future.

The promise of AI agents is that users can leverage the technology to complete complicated tasks in a more sophisticated, often autonomous, way. In his latest [AI series](https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html), Ezra Klein gave a nice illustration of the agentic future:

> *“The example I always use in my head is, when can I tell an AI, my son is turning five. He loves dragons. We live in Brooklyn. Give me some options for planning his birthday party. And then, when I choose between them, can you just do it all for me? Order the cake, reserve the room, send out the invitations, whatever it might be.”*

Today’s general-purpose models are broadly useful, but they do not have the grounding to effectively execute a specific task like this. (Imagine using ChatGPT today to plan Ezra’s son’s birthday. Maybe it would provide a bit of inspiration, a few theme ideas, but it wouldn’t carry real weight in *planning* the party.)

To tackle more complicated tasks, [agentic workflows](https://www.youtube.com/watch?v=sal78ACtGTc) wrap large language models in more sophisticated “chains” of actions, allowing the LLM to dissect complicated tasks into individual steps and reason more effectively along the way.

Agentic Workflows

Using Ezra’s example, a birthday planning *agent,* or team of agents, could be given a chain of 30 steps to follow in planning a birthday — from running an analysis of Brooklyn trends to conducting a competitive audit of cake vendors to checking their work along the way. The system of steps creates the grounding an LLM needs to accurately and sophisticatedly tackle tasks — rather than today’s “zero-shot” prompts.

This agentic boost to LLMs lays the groundwork for our new UX paradigm.

## A vision for agentic UX

It’s design’s job to confidently illustrate the future of digital experience; however, we need to build a collective intuition for what that looks like.

The last time we switched UX paradigms — from physical to digital — it was much easier to communicate the opportunity to business leaders because “[the medium was the message](https://www.smashingmagazine.com/2011/07/the-medium-is-the-message/).” When we referenced a “web experience” or “mobile experience,” the platform itself conjured up a clear vision and value prop.

Saying “AI experience” or “AI-powered” doesn’t have the same effect. The technology is too broad and misunderstood to illustrate a shared vision. On the other hand, narrowing in on “conversational interfaces” or the new interaction pattern alone doesn’t showcase the transformative opportunity.

I think Kwame Nyanning was onto something when he [stumbled upon](https://www.linkedin.com/feed/update/urn:li:activity:7153385059113181184/) the term ‘Agentic UX.’ It fulfills the need to be specific yet visionary. Even more importantly, it matches the trajectory of the core technology.

In my opinion, the essence of this new paradigm is simple:

-   In traditional digital experiences, we’ve created scaffolding to support users along their journey, but we’ve expected them to do the necessary thinking, planning, and navigating to complete a task.
-   In an agentic UX, a user is continuously supported by a built-in agent that pulls real weight, transforming every digital experience from a solo endeavor to a partner-based journey.

Agentic UX

In an Agentic UX, an AI agent pulls weight across 3 categories: cognitive, creative, and logistical.

-   **Cognitive weight** — the built-in agent pulls analysis and decision-making weight
-   **Creative weight** — the built-in agent takes on visualization and media creation weight
-   **Logistical weight** — the built-in agent takes tasks on operational and workflow weight

Early examples of the agentic future of UX are already appearing today. [Adobe’s Gen Studio](https://business.adobe.com/products/genstudio.html#demo-video), [Intercom’s Copilot](https://www.youtube.com/watch?v=XYK2VI_MbSk), and [Dovetail’s Magic Experience](https://dovetail.com/blog/just-like-magic-dovetails-newest-features-are-here/) are some of my favorite windows into the future of digital experiences.

From a UX point of view, I don’t think it matters if the AI agent is labeled as an “agent” or if it exists as a collection of unbranded agentic features. The defining criteria is that a user is continuously supported by an AI that pulls real weight.

For instance, Dovetail launched an agentic UX in April of 2024, branded as a suite of ‘[Magic’](https://dovetail.com/blog/just-like-magic-dovetails-newest-features-are-here/) features. The traditional digital experience provides the scaffolding for the user to get their job done — but nothing more. (Dovetail is a SaaS product that allows users to upload qualitative data from an interview video or transcript and analyze that data by coding and clustering.)

In its agentic experience, the platform becomes more of a research teammate than a piece of software, supporting users with cognitive and logistical partnerships throughout the entire journey — summarizing the transcript, providing highlight suggestions, and assisting with clustering.

In this nascent experience, the AI agent plays a supportive role rather than autonomously acting on the user’s behalf; however, as the training data and technology improve, the agentic scope will expand over time.

## Strategically reinvent your digital experience for the agentic era.

The new UX paradigm represents a massive opportunity for every company — or, conversely, a massive competitive vulnerability to ignore. Yet, what’s still missing is the enthusiasm and buy-in from leadership needed to get them to embrace the transformative change.

Empathetically, companies have been consumed by ‘AI readiness’ as they’ve laid the foundational infrastructure and governance. In addition, in the first chapters of the AI era, where so much has changed so quickly, it’s been hard to clearly see the future from within the tornado.

Eventually, the shape and value of an agentic UX will become second nature to business leaders. However, until that point, it becomes the job of design to step into a strategic role and vividly bring the future to life — in a way that leadership can see, feel, and get incredibly excited about.

This likely requires a dedicated visioning initiative, a “future of digital experience” effort, to explore future growth and competitive advantage. This effort doesn’t have to be a significant drain on resources. The purpose is to take a step back and strategically reimagine rather than immediately running a frenzied proof of concept.

**I recommend following this high-level approach:**

1.  Revisit all of your critical user journeys.
2.  At each step of the journey, examine the cognitive, logistical, and creative burdens placed on the user’s shoulders — or, more broadly, the places where they are most alone.
3.  For each step of the journey, examine how you can apply the unique capabilities of an AI agent to support the user’s task.
4.  Vividly bring it to life. Paint the picture vividly to show how much value is on the table.

It’s been a gloomy year for the design discipline. We’ve been forced through harsh layoffs and reckoning of design’s inherent value. But the strategic winds are at our backs again, and it’s time we raise the sails.

*This article was originally published in* [*Empathy & AI*](https://empathyandai.beehiiv.com/), *follow for more human-centered AI content or reach out on* [*Linkedin*](https://www.linkedin.com/in/alexcklein/)*.*

## References

-   Fortune [https://fortune.com/2023/04/17/sundar-pichai-a-i-more-profound-than-fire-electricity/](https://fortune.com/2023/04/17/sundar-pichai-a-i-more-profound-than-fire-electricity/)
-   Exploring the spectrum of “Needfulness” in AI Products, Emily Campbell [https://shapeofai.substack.com/p/exploring-the-spectrum-of-needfulness](https://shapeofai.substack.com/p/exploring-the-spectrum-of-needfulness)
-   Loom AI Launch [https://www.loom.com/ai](https://www.loom.com/ai)
-   Sam Altman says helpful agents are poised to become AI’s killer function, MIT Tech Review [https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-helpful-agents-are-poised-to-become-ais-killer-function/](https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-helpful-agents-are-poised-to-become-ais-killer-function/)
-   Google’s AI Boss Says Scale Only Gets You So Far, Wired [https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artificial-intelligence-scale/?source=Email\_0\_EDT\_WIR\_NEWSLETTER\_0\_TRANSPORTATION\_ZZ&bxid=&cndid=&esrc=](https://www.wired.com/story/deepmind-ceo-demis-hassabis-interview-artificial-intelligence-scale/?bxid=&cndid=&esrc=)
-   Transcript: Ezra Klein Interviews Dario Amodei, NYT [https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html](https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html)
-   What’s next for agnetic workflow, Andrew Ng [https://www.youtube.com/watch?v=sal78ACtGTc](https://www.youtube.com/watch?v=sal78ACtGTc)
-   Kwame Nyanning, [https://www.linkedin.com/feed/update/urn:li:activity:7153385059113181184/](https://www.linkedin.com/feed/update/urn:li:activity:7153385059113181184/)
-   Adobe Gen Studio [https://business.adobe.com/products/genstudio.html#demo-video](https://business.adobe.com/products/genstudio.html#demo-video)
-   Intercom’s Fin Copilot [https://www.youtube.com/watch?v=XYK2VI\_MbSk](https://www.youtube.com/watch?v=XYK2VI_MbSk)
-   Dovetails Magic Experience [https://dovetail.com/blog/just-like-magic-dovetails-newest-features-are-here/](https://dovetail.com/blog/just-like-magic-dovetails-newest-features-are-here/)